{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Session 4","provenance":[{"file_id":"1wjeQUu-LncFG9D88JkrYK24GE3ElEwvP","timestamp":1581441761869},{"file_id":"15iNLVEpVnAHsNmRiBFXGIwW-rZEhLtuj","timestamp":1581411627506},{"file_id":"1uJZvJdi5VprOQHROtJIHy0mnY2afjNlx","timestamp":1580194487395}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0m2JWFliFfKT","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h_Cx9q2QFgM7","colab_type":"code","colab":{}},"source":["class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        \n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(1, 16, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(16, 16, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(16, 16, 3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            nn.MaxPool2d(2, 2),\n","        )\n","        \n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(16, 32, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(32, 32, 3, padding=1),\n","            nn.ReLU(),\n","            nn.Conv2d(32, 32, 3, stride=2, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(32),\n","            nn.MaxPool2d(2, 2),\n","        )\n","        \n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(32, 64, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","        )\n","        \n","        self.fc = nn.Sequential(\n","            nn.Linear(64, 10)\n","        )\n","                \n","        \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        \n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","        x = F.log_softmax(x, dim=1)\n","        return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VqvpC6HXq9Hc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xdydjYTZFyi3","outputId":"f0dae2cc-5f8c-491d-b5b1-da4e3a94dabc","executionInfo":{"status":"ok","timestamp":1581445051278,"user_tz":-330,"elapsed":8402,"user":{"displayName":"Prasad Shripathi","photoUrl":"","userId":"01122758420514335828"}},"colab":{"base_uri":"https://localhost:8080/","height":607}},"source":["!pip install torchsummary\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Model().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 16, 28, 28]             160\n","              ReLU-2           [-1, 16, 28, 28]               0\n","            Conv2d-3           [-1, 16, 28, 28]           2,320\n","              ReLU-4           [-1, 16, 28, 28]               0\n","            Conv2d-5           [-1, 16, 14, 14]           2,320\n","              ReLU-6           [-1, 16, 14, 14]               0\n","       BatchNorm2d-7           [-1, 16, 14, 14]              32\n","         MaxPool2d-8             [-1, 16, 7, 7]               0\n","            Conv2d-9             [-1, 32, 7, 7]           4,640\n","             ReLU-10             [-1, 32, 7, 7]               0\n","           Conv2d-11             [-1, 32, 7, 7]           9,248\n","             ReLU-12             [-1, 32, 7, 7]               0\n","           Conv2d-13             [-1, 32, 4, 4]           9,248\n","             ReLU-14             [-1, 32, 4, 4]               0\n","      BatchNorm2d-15             [-1, 32, 4, 4]              64\n","        MaxPool2d-16             [-1, 32, 2, 2]               0\n","           Conv2d-17             [-1, 64, 2, 2]          18,496\n","             ReLU-18             [-1, 64, 2, 2]               0\n","        MaxPool2d-19             [-1, 64, 1, 1]               0\n","           Linear-20                   [-1, 10]             650\n","================================================================\n","Total params: 47,178\n","Trainable params: 47,178\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.53\n","Params size (MB): 0.18\n","Estimated Total Size (MB): 0.71\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DqTWLaM5GHgH","colab_type":"code","colab":{}},"source":["\n","\n","torch.manual_seed(1)\n","batch_size = 128\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","train_loader = torch.utils.data.DataLoader(\n","  datasets.MNIST ('../data', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fDefDhaFlwH","colab_type":"code","colab":{}},"source":["from tqdm import tqdm\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    pbar = tqdm(train_loader)\n","    for batch_idx, (data, target) in enumerate(pbar):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n","\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MMWbLWO6FuHb","colab_type":"code","outputId":"d789239b-70a7-4e92-9722-d275527318da","executionInfo":{"status":"ok","timestamp":1581445319136,"user_tz":-330,"elapsed":276225,"user":{"displayName":"Prasad Shripathi","photoUrl":"","userId":"01122758420514335828"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","model = Model().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(0, 20):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["loss=0.05075454339385033 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.42it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0515, Accuracy: 9847/10000 (98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.04334553703665733 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.74it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0372, Accuracy: 9875/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.04312534257769585 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 38.49it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0306, Accuracy: 9893/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.003341391682624817 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 38.92it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0265, Accuracy: 9908/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.03756235912442207 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.82it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0290, Accuracy: 9903/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.03866272047162056 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.99it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0344, Accuracy: 9900/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.002312173368409276 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 40.03it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0238, Accuracy: 9923/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.14516067504882812 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.87it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0298, Accuracy: 9905/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0006132026319392025 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.25it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0306, Accuracy: 9907/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.001978253247216344 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.56it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0265, Accuracy: 9923/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0019540786743164062 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.70it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0216, Accuracy: 9928/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0010881870985031128 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.82it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0247, Accuracy: 9921/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.00011849403381347656 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 39.01it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0223, Accuracy: 9935/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0009775608777999878 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.73it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0225, Accuracy: 9932/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0004401405749376863 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.48it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0209, Accuracy: 9939/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0003403623995836824 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.55it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0211, Accuracy: 9936/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0006152887945063412 batch_id=468: 100%|██████████| 469/469 [00:12<00:00, 38.91it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0211, Accuracy: 9936/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=5.2928924560546875e-05 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.46it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0212, Accuracy: 9944/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.00023330251860897988 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.45it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0216, Accuracy: 9941/10000 (99%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.00011759003245970234 batch_id=468: 100%|██████████| 469/469 [00:11<00:00, 39.70it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0217, Accuracy: 9940/10000 (99%)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"So5uk4EkHW6R","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}